#!/usr/bin/env pandda.python

###############################################################################
# Packages
##############################################################################
import copy
import glob
import libtbx.phil
#################################
import matplotlib
import numpy
import os
import pandas
import sys

matplotlib.use('Agg')
matplotlib.interactive(0)
from matplotlib import pyplot
pyplot.style.use('ggplot')
import matplotlib.lines as mlines
##################################
import multiprocessing as mp

###########################################################
# Function imports
##########################################################

# Ringer Processing with absolute electron density scaling (F000)
from process import process_with_ringer
# Sorting & Interpolating angles from ringer output
from multiple_dataset_ringer.process.interpolate import (linear_interpolate_ringer_results,
                                                         normalise_and_sort_ringer_results)
# Peak finding
from multiple_dataset_ringer.peaks.peak_count import (find_peaks, find_peakutils)
from multiple_dataset_ringer.peaks.peak_to_array import peak_to_array

# Alternate Conformer Spatial Map
from multiple_dataset_ringer.contact_map.pdb_to_dist import (spatial_conformer_matrix, print_conformer_matrix,
                                                             print_all_alt_conformer)

###############################################################################
#sk Set up for passing arguments
############################################################################### 

blank_arg_prepend = {None:'dir=', '.pdb':'pdb=', '.mtz':'mtz='}

master_phil = libtbx.phil.parse("""
input {
    dir = None
        .type = path
        .multiple = True
    pdb_style = "*.dimple.pdb"
        .type = str
        .multiple = False
    mtz_style = "*.dimple.mtz"
      .type = str
        .multiple = False
}
output {
    log = "ringer.log"
        .type = str
        .multiple = False
}
settings {
    # XXX mmtbx.ringer can only take this an integer, >1 XXX#
    angle_sampling = 2
        .type = int
        .multiple = False

    gen_heatmap = False
        .type = bool
        .multiple = False
    processes = 6
        .type = int
        .multiple = False
}
""")

###############################################################################
# Logging
###############################################################################
import logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
fh = logging.FileHandler('ringer_script.log')
fh.setLevel(logging.DEBUG)
fh.setFormatter(formatter)
logger.addHandler(fh)

ch = logging.StreamHandler()
ch.setLevel(logging.DEBUG)
ch.setFormatter(formatter)
logger.addHandler(ch)

################################################################################
#                                   FUNCTIONS                                  #
################################################################################

def ringer_all_datasets(dir,params):

    # Label the dataset by the directory name
    dataset_label = os.path.basename(dir)
    pdb = glob.glob(os.path.join(dir, params.input.pdb_style))
    mtz = glob.glob(os.path.join(dir, params.input.mtz_style))
    assert pdb, 'No PDB Files found in {} matching {}'.format(dir, params.input.pdb_style)
    assert mtz, 'No MTZ Files found in {} matching {}'.format(dir, params.input.mtz_style)
    pdb = pdb[0]
    mtz = mtz[0]

    # Process dataset with ringer and convert results to DataFrame
    ringer_csv, resolution = process_with_ringer(pdb=pdb, mtz=mtz, angle_sampling=params.settings.angle_sampling,
                                                 output_dir=dir)

    ringer_results = pandas.DataFrame.from_csv(ringer_csv, header=None)

    # Change order of residue name
    for i in range(0,len(ringer_results.index)):
        res_split = ringer_results.index.values[i].rsplit(' ')
        res_split.remove('')
        ringer_results.index.values[i] = res_split[2] + ' ' + res_split[0] + ' ' + res_split[1]    

    
    return ringer_results, dataset_label                                                
##############################################################################
# Main program 
###############################################################################

def run(params):

    # Dictionary to store all of the 
    # ringer results for each of the 
    # datasets
    all_results = {}

    # Create an output directory if it doesn't already exist 
    out_dir = 'Processed_data_ABS'
    if not os.path.isdir(out_dir):
        os.makedirs(out_dir)
    
    # Generate ringer results 
    # TODO Assess why multiprocessing is not offering a speed up 
    #      Possibly due to command manager

    pool = mp.Pool(processes = params.settings.processes)
    results = [pool.apply(ringer_all_datasets, 
                                      args=(dir,params)) 
                                      for dir in params.input.dir]
    for item in results:
        all_results[item[1]]=item[0]
 
    # Pull out the "first" ringer results set as a reference
    ref_set = all_results.values()[0]

    # Map and angle types currently selected to analyse
    map_type = '2mFo-DFc'
    angle_type = 'chi1'

    # Name for storage of interpolated results (without residue)
    interpolate_base_csv = '_{}_Datasets_{}_{}-ringer.csv'.format(len(params.input.dir),map_type,angle_type)

    #Choose a map_type/angle_type by reducing reference set
    ref_set=ref_set.loc[(ref_set[1] == map_type)]
    ref_set=ref_set.loc[(ref_set[2] == angle_type)]

    # Iterate through the residues
    for residue, data in ref_set.iterrows():
       residue_data_list = []
        
        # Create ouput directories for each residue
       if not os.path.isdir(os.path.join(out_dir,residue)):
           os.makedirs(os.path.join(out_dir,residue))
        # Output filename for interpolated data 
        # (Used to check existence of output)
       interpolate_csv = residue + interpolate_base_csv       
        
       if not os.path.exists(os.path.join(out_dir,residue,interpolate_csv)):
        
            # Iterate through the datasets
           for dataset_label, dataset_results in all_results.iteritems():
                 
               current_dataset_results = dataset_results.loc[(dataset_results.index == residue)]    
               sorted_angles, sorted_map_values = normalise_and_sort_ringer_results(current_dataset_results, params=params)
               interpolated_angles,interpolated_map_values = linear_interpolate_ringer_results(sorted_angles,sorted_map_values,angle_sampling=params.settings.angle_sampling)          
                
               # Store these in a list
               residue_data_list.append((interpolated_angles, 
                                         interpolated_map_values))
               # If it doesn't exist: Create dataframe to store results from 
               # one residue, across multiple datasets 
               if not 'single_residue_multiple_datasets' in locals():
                   single_residue_multiple_datasets = pandas.DataFrame(
                                                      columns = 
                                                      interpolated_angles)

               # Populate dataframe with results from one residue, 
               # across multiple datasets 
               single_residue_multiple_datasets.loc['{}'.format(dataset_label)]                                                    = interpolated_map_values        

           # Output CSV from one resiude, multiple datasets
           pandas.DataFrame.to_csv(single_residue_multiple_datasets,
                                   os.path.join(out_dir,residue,
                                                interpolate_csv))
       else:
           logger.info(('{}:Interpolated CSVs already generated, for these {} '
                       'datasets'.format(residue,len(params.input.dir))))

    ###########################################################################
    # Peak Finding Routine
    ###########################################################################
    #min_dist = 0
    threshold = 0.0
    peak_filename = "Peak_positions_thres_0_using_peakdetect.csv"
    if not os.path.exists(os.path.join(out_dir,peak_filename)):
       find_peaks(out_dir, ref_set, params, map_type, angle_type, 
                   peak_filename, threshold = threshold)
                   #, mpd = min_dist, 
                   #threshold = threshold)
       #find_peakutils(out_dir, ref_set, params, map_type, angle_type, 
       #               peak_filename, min_dist = min_dist, 
       #               threshold = threshold)
    else:
        logger.info('Peak Positions already generated')

    ###########################################################################
    # Alternate conformer array generation from peak information
    ###########################################################################
    conformer_dir ='Alt_conformer_intensity_test'
    conformer_base_filename ='_Alt_confomer.csv'

    peak_to_array(out_dir,conformer_dir,peak_filename,conformer_base_filename)
    ###########################################################################
    # Generating Spatial Alternate confomer Map
    #
    # Use pconpy to generate contact maps.
    ############################################################################     

    sum_conformer_spatial_mat = None

    for dataset, dataset_results in all_results.iteritems():
        img_filename = dataset + '_' + 'AltConf.png'
        # PDB file to generate contact map from
        pdb_filepath = os.path.join(dataset, dataset + 
                                    params.input.pdb_style.lstrip('*'))  
        conformer_csv_filename = dataset  + conformer_base_filename

        img_filename_no_spatial = dataset + '_' + 'AllAltConf.png'
        
        if not os.path.exists(os.path.join(out_dir,conformer_dir,img_filename)):
            
            # Looking at alternate conformer without spatial information
            #print_all_alt_conformer(os.path.join(out_dir,conformer_dir,
            #                        conformer_csv_filename),pdb_filepath,
            #                        os.path.join(out_dir,conformer_dir),
            #                        img_filename_no_spatial,
            #                        title = 'Dataset:' + dataset + 
            #                                'All Alternate conformers')
            (conformer_spatial_mat, contact_matrix) = spatial_conformer_matrix(
                                os.path.join(out_dir,conformer_dir,
                                            conformer_csv_filename),
                                pdb_filepath, measure ='CB', dist_thres = 8.0)
            #print_conformer_matrix(out_dir=os.path.join(out_dir,conformer_dir),
            #                       img_filename = img_filename,
            #                       conformer_spatial_mat=conformer_spatial_mat,
            #                       contact_map = contact_matrix, 
            #                       title = 'Dataset:' + dataset + 
            #                          'Alternate Conformer matrix')
            if sum_conformer_spatial_mat is None:
                sum_conformer_spatial_mat = conformer_spatial_mat
            else:
                sum_conformer_spatial_mat = sum_conformer_spatial_mat.add(conformer_spatial_mat) 
        else:
            logger.info(img_filename + "Already generated")
    
    # Calculate & Print intensity map
    sum_conformer_spatial_mat = sum_conformer_spatial_mat.divide(len(params.input.dir))
    from IPython import embed; embed()
    print_conformer_matrix(out_dir = os.path.join(out_dir,conformer_dir),
                               img_filename = 'intensity',
                               conformer_spatial_mat = sum_conformer_spatial_mat,
                               contact_map = None, sum_intensity = True,
                               title = 'Intensity spatial map') 
#For allowing command manager 
if __name__ == '__main__':
    from giant.jiffies import run_default
    run_default(run=run, master_phil=master_phil, args=sys.argv[1:], blank_arg_prepend=blank_arg_prepend)
